{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/simoninithomas/d6adc6edb0a7f37d6323a5e3d2ab72ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "from vizdoom import *        # Doom Environment\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "import random                # Handling random number generation\n",
    "import time                  # Handling time calculation\n",
    "from skimage import transform# Help us to preprocess the frames\n",
    "\n",
    "from collections import deque# Ordered collection with ends\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "\n",
    "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create our environment üéÆ\n",
    "- Now that we imported the libraries/dependencies, we will create our environment.\n",
    "- Doom environment takes:\n",
    "    - A `configuration file` that **handle all the options** (size of the frame, possible actions...)\n",
    "    - A `scenario file`: that **generates the correct scenario** (in our case basic **but you're invited to try other scenarios**).\n",
    "- Note: We have 3 possible actions: turn left, turn right, shoot (attack)... so we don't need to do one hot encoding (thanks to <a href=\"https://stackoverflow.com/users/2237916/silgon\">silgon</a> for figuring out). \n",
    "\n",
    "<br>\n",
    "REWARDS:\n",
    "\n",
    "- death penalty = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we create our environment\n",
    "\"\"\"\n",
    "def create_environment():\n",
    "    game = DoomGame()\n",
    "\n",
    "    # Load the correct configuration\n",
    "    game.load_config('VizDoom/scenarios/basic.cfg')\n",
    "\n",
    "    # Load the correct scenario (in our case basic)\n",
    "    game.set_doom_scenario_path('VizDoom/scenarios/basic.wad')\n",
    "\n",
    "    game.set_window_visible(False) #no pop out window\n",
    "    game.init()\n",
    "\n",
    "    # Here we create an hot encoded version of our actions (3 possible actions)\n",
    "    possible_actions = np.identity(3,dtype=int).tolist()\n",
    "\n",
    "    return game, possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "files_and_directories = os.listdir(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game, possible_actions = create_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the preprocessing functions ‚öôÔ∏è\n",
    "### preprocess_frame\n",
    "Preprocessing is an important step, <b>because we want to reduce the complexity of our states to reduce the computation time needed for training.</b>\n",
    "<br><br>\n",
    "Our steps:\n",
    "- Grayscale each of our frames (because <b> color does not add important information </b>). But this is already done by the config file.\n",
    "- Crop the screen (in our case we remove the roof because it contains no information)\n",
    "- We normalize pixel values\n",
    "- Finally we resize the preprocessed frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    preprocess_frame:\n",
    "    Take a frame.\n",
    "    Resize it.\n",
    "        __________________\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |_________________|\n",
    "\n",
    "        to\n",
    "        _____________\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        |____________|\n",
    "    Normalize it.\n",
    "\n",
    "    return preprocessed_frame\n",
    "\n",
    "    \"\"\"\n",
    "def preprocess_frame(frame):\n",
    "    # Crop the screen (remove part that contains no information)\n",
    "    # [Up: Down, Left: right]\n",
    "    cropped_frame = frame[15:-5, 20:-20]\n",
    "\n",
    "    # Check if the cropped frame has non-zero dimensions\n",
    "    if cropped_frame.size == 0:\n",
    "        # If the cropped frame has zero dimensions, return a default frame with zeros\n",
    "        return np.zeros((100, 120), dtype=np.float32)\n",
    "\n",
    "    # Normalize Pixel Values\n",
    "    normalized_frame = cropped_frame / 255.0\n",
    "\n",
    "    # Resize\n",
    "    preprocessed_frame = transform.resize(cropped_frame, [100, 120])\n",
    "\n",
    "    return preprocessed_frame # 100x120x1 frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack_frames\n",
    "üëè This part was made possible thanks to help of <a href=\"https://github.com/Miffyli\">Anssi</a><br>\n",
    "\n",
    "As explained in this really <a href=\"https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\">  good article </a> we stack frames.\n",
    "\n",
    "Stacking frames is really important because it helps us to **give have a sense of motion to our Neural Network.**\n",
    "\n",
    "- First we preprocess frame\n",
    "- Then we append the frame to the deque that automatically **removes the oldest frame**\n",
    "- Finally we **build the stacked state**\n",
    "\n",
    "This is how work stack:\n",
    "- For the first frame, we feed 4 frames\n",
    "- At each timestep, **we add the new frame to deque and then we stack them to form a new stacked frame**\n",
    "- And so on\n",
    "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/DQN/Space%20Invaders/assets/stack_frames.png\" alt=\"stack\">\n",
    "- If we're done, **we create a new stack with 4 new frames (because we are in a new episode)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames  =  deque([np.zeros((100,120), dtype=int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    if state.size == 0:\n",
    "        # Return the existing stacked frames without modification\n",
    "        return np.stack(stacked_frames, axis=2), stacked_frames\n",
    "\n",
    "    # Preprocess frame\n",
    "    frame = preprocess_frame(state)\n",
    "\n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros((100,120), dtype=int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "\n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Build the stacked state (first dimension specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "\n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up our hyperparameters ‚öóÔ∏è\n",
    "In this part we'll set up our different hyperparameters. But when you implement a Neural Network by yourself you will **not implement hyperparamaters at once but progressively**.\n",
    "\n",
    "- First, you begin by defining the neural networks hyperparameters when you implement the model.\n",
    "- Then, you'll add the training hyperparameters when you implement the training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [100,120,4]      # Our input is a stack of 4 frames hence 100x120x4 (Width, height, channels)\n",
    "action_size = game.get_available_buttons_size()              # 3 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 500         # Total episodes for training\n",
    "max_steps = 100             # Max possible steps in an episode\n",
    "batch_size = 64\n",
    "\n",
    "# FIXED Q TARGETS HYPERPARAMETERS\n",
    "max_tau = 10000 #Tau is the C step where we update our target network\n",
    "\n",
    "# EXPLORATION HYPERPARAMETERS for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability\n",
    "decay_rate = 0.00005            # exponential decay rate for exploration prob\n",
    "\n",
    "# Q LEARNING hyperparameters\n",
    "gamma = 0.95               # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "## If you have GPU change to 1million\n",
    "pretrain_length = 10             # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 10 ##100000                 # Number of experiences the Memory can keep\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Dueling Double Deep Q-learning Neural Network model (aka DDDQN) üß†\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1500/1*FkHqwA2eSGixdS-3dvVoMA.png\" alt=\"Dueling Double Deep Q Learning Model\" />\n",
    "This is our Dueling Double Deep Q-learning model:\n",
    "- We take a stack of 4 frames as input\n",
    "- It passes through 3 convnets\n",
    "- Then it is flatened\n",
    "- Then it is passed through 2 streams\n",
    "    - One that calculates V(s)\n",
    "    - The other that calculates A(s,a)\n",
    "- Finally an agregating layer\n",
    "- It outputs a Q value for each actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDDQNNet:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.name = name\n",
    "        random_var = 64\n",
    "        \n",
    "        \n",
    "        # We use tf.variable_scope here to know which network we're using (DQN or target_net)\n",
    "        # it will be useful when we will update our w- parameters (by copy the DQN parameters)\n",
    "        with tf.compat.v1.variable_scope(self.name):\n",
    "            \n",
    "            # We create the placeholders\n",
    "            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
    "            # [None, 100, 120, 4]\n",
    "            self.inputs_ = tf.compat.v1.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
    "            \n",
    "            #\n",
    "            self.ISWeights_ = tf.compat.v1.placeholder(tf.float32, [None,1], name='IS_weights')\n",
    "            \n",
    "            self.actions_ = tf.placeholder(tf.float32, [random_var, action_size], name=\"actions_\")\n",
    "            \n",
    "            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "            self.target_Q = tf.compat.v1.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            \"\"\"\n",
    "            First convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            # Input is 100x120x4\n",
    "            self.conv1 = Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=[8, 8],\n",
    "                    strides=[4, 4],\n",
    "                    padding=\"VALID\",\n",
    "                    kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                    name=\"conv1\")(self.inputs_)\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Second convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            self.conv2 = Conv2D(\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                 name = \"conv2\")(self.conv1_out)\n",
    "\n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Third convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            self.conv3 = Conv2D(\n",
    "                                 filters = 128,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                 name = \"conv3\")(self.conv2_out)\n",
    "\n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            \n",
    "            self.flatten = Flatten(data_format='channels_last')(self.conv3)\n",
    "            \n",
    "            \n",
    "            ## Here we separate into two streams\n",
    "            # The one that calculate V(s)\n",
    "            self.value_fc = Dense(\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"value_fc\")(self.flatten)\n",
    "            \n",
    "            self.value = Dense(\n",
    "                                        units = 1,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"value\")(self.value_fc)\n",
    "            \n",
    "            # The one that calculate A(s,a)\n",
    "            self.advantage_fc = Dense(\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"advantage_fc\")(self.flatten)\n",
    "            \n",
    "            self.advantage = Dense(\n",
    "                                        units = self.action_size,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"advantages\")(self.advantage_fc)\n",
    "            \n",
    "            # Agregating layer\n",
    "            # Q(s,a) = V(s) + (A(s,a) - 1/|A| * sum A(s,a'))\n",
    "            self.output = self.value + tf.subtract(self.advantage, tf.reduce_mean(self.advantage, axis=1, keepdims=True))\n",
    "              \n",
    "            # Q is our predicted Q value.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_), axis=1)\n",
    "            \n",
    "            # The loss is modified because of PER \n",
    "            self.absolute_errors = tf.abs(self.target_Q - self.Q)# for updating Sumtree\n",
    "            \n",
    "            self.loss = tf.reduce_mean(self.ISWeights_ * tf.math.squared_difference(self.target_Q, self.Q))\n",
    "            \n",
    "            self.optimizer = tf.compat.v1.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yeungivan/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/training/rmsprop.py:188: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Reset the graph\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"DQNetwork\")\n",
    "\n",
    "# Instantiate the target network\n",
    "TargetNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"TargetNetwork\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prioritized Experience Replay üîÅ\n",
    "Now that we create our Neural Network, **we need to implement the Prioritized Experience Replay method.** <br>\n",
    "\n",
    "As explained in the article, **we can't use a simple array to do that because sampling from it will be not efficient, so we use a binary tree data type (in a binary tree each node has no + than 2 children).** More precisely, a sumtree, which is a binary tree where parents nodes are the sum of the children nodes.\n",
    "\n",
    "If you don't know what is a binary tree check this awesome video https://www.youtube.com/watch?v=oSWTXtMglKE\n",
    "\n",
    "\n",
    "This SumTree implementation was taken from Morvan Zhou in his chinese course about Reinforcement Learning\n",
    "\n",
    "To summarize:\n",
    "- **Step 1**: We construct a SumTree, which is a Binary Sum tree where leaves contains the priorities and a data array where index points to the index of leaves.\n",
    "    <img src=\"https://cdn-images-1.medium.com/max/1200/1*Go9DNr7YY-wMGdIQ7HQduQ.png\" alt=\"SumTree\"/>\n",
    "    <br><br>\n",
    "    - **def __init__**: Initialize our SumTree data object with all nodes = 0 and data (data array) with all = 0.\n",
    "    - **def add**: add our priority score in the sumtree leaf and experience (S, A, R, S', Done) in data.\n",
    "    - **def update**: we update the leaf priority score and propagate through tree.\n",
    "    - **def get_leaf**: retrieve priority score, index and experience associated with a leaf.\n",
    "    - **def total_priority**: get the root node value to calculate the total priority score of our replay buffer.\n",
    "<br><br>\n",
    "- **Step 2**: We create a Memory object that will contain our sumtree and data.\n",
    "    - **def __init__**: generates our sumtree and data by instantiating the SumTree object.\n",
    "    - **def store**: we store a new experience in our tree. Each new experience will **have priority = max_priority** (and then this priority will be corrected during the training (when we'll calculating the TD error hence the priority score).\n",
    "    - **def sample**:\n",
    "         - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
    "         - Then a value is uniformly sampled from each range\n",
    "         - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "         - Then, we calculate IS weights for each minibatch element\n",
    "    - **def update_batch**: update the priorities on the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version of Morvan Zhou:\n",
    "    https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5.2_Prioritized_Replay_DQN/RL_brain.py\n",
    "    \"\"\"\n",
    "    data_pointer = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Here we initialize the tree with all nodes = 0, and initialize the data with all values = 0\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # Number of leaf nodes (final nodes) that contains experiences\n",
    "\n",
    "        # Generate the tree with all nodes values = 0\n",
    "        # To understand this calculation (2 * capacity - 1) look at the schema above\n",
    "        # Remember we are in a binary node (each node has max 2 children) so 2x size of leaf (capacity) - 1 (root node)\n",
    "        # Parent nodes = capacity - 1\n",
    "        # Leaf nodes = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "\n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "        0  0 0  0  [Size: capacity] it's at this line that there is the priorities score (aka pi)\n",
    "        \"\"\"\n",
    "\n",
    "        # Contains the experiences (so the size of data is capacity)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Here we add our priority score in the sumtree leaf and add the experience in data\n",
    "    \"\"\"\n",
    "    def add(self, priority, data):\n",
    "        # Look at what index we want to put the experience\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "\n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "tree_index  0 0  0  We fill the leaves from left to right\n",
    "        \"\"\"\n",
    "\n",
    "        # Update data frame\n",
    "        self.data[self.data_pointer] = data\n",
    "\n",
    "        # Update the leaf\n",
    "        self.update (tree_index, priority)\n",
    "\n",
    "        # Add 1 to data_pointer\n",
    "        self.data_pointer += 1\n",
    "\n",
    "        if self.data_pointer >= self.capacity:  # If we're above the capacity, you go back to first index (we overwrite)\n",
    "            self.data_pointer = 0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Update the leaf priority score and propagate the change through tree\n",
    "    \"\"\"\n",
    "    def update(self, tree_index, priority):\n",
    "        # Change = new priority score - former priority score\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "\n",
    "        # then propagate the change through tree\n",
    "        while tree_index != 0:    # this method is faster than the recursive loop in the reference code\n",
    "\n",
    "            \"\"\"\n",
    "            Here we want to access the line above\n",
    "            THE NUMBERS IN THIS TREE ARE THE INDEXES NOT THE PRIORITY VALUES\n",
    "\n",
    "                0\n",
    "               / \\\n",
    "              1   2\n",
    "             / \\ / \\\n",
    "            3  4 5  [6]\n",
    "\n",
    "            If we are in leaf at index 6, we updated the priority score\n",
    "            We need then to update index 2 node\n",
    "            So tree_index = (tree_index - 1) // 2\n",
    "            tree_index = (6-1)//2\n",
    "            tree_index = 2 (because // round the result)\n",
    "            \"\"\"\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Here we get the leaf_index, priority value of that leaf and experience associated with that index\n",
    "    \"\"\"\n",
    "    def get_leaf(self, v):\n",
    "        \"\"\"\n",
    "        Tree structure and array storage:\n",
    "        Tree index:\n",
    "             0         -> storing priority sum\n",
    "            / \\\n",
    "          1     2\n",
    "         / \\   / \\\n",
    "        3   4 5   6    -> storing priority for experiences\n",
    "        Array type for storing:\n",
    "        [0,1,2,3,4,5,6]\n",
    "        \"\"\"\n",
    "        parent_index = 0\n",
    "\n",
    "        while True: # the while loop is faster than the method in the reference code\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "\n",
    "            # If we reach bottom, end the search\n",
    "            if left_child_index >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "\n",
    "            else: # downward search, always search for a higher priority node\n",
    "\n",
    "                if v <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "\n",
    "                else:\n",
    "                    v -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "\n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "\n",
    "        return leaf_index, self.tree[leaf_index], self.data[data_index]\n",
    "\n",
    "    @property\n",
    "    def total_priority(self):\n",
    "        return self.tree[0] # Returns the root node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't use deque anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version and the original code is from:\n",
    "    https://github.com/jaara/AI-blog/blob/master/Seaquest-DDQN-PER.py\n",
    "    \"\"\"\n",
    "    PER_e = 0.01  # Hyperparameter that we use to avoid some experiences to have 0 probability of being taken\n",
    "    PER_a = 0.6  # Hyperparameter that we use to make a tradeoff between taking only exp with high priority and sampling randomly\n",
    "    PER_b = 0.4  # importance-sampling, from initial value increasing to 1\n",
    "\n",
    "    PER_b_increment_per_sampling = 0.001\n",
    "\n",
    "    absolute_error_upper = 1.  # clipped abs error\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Making the tree\n",
    "        \"\"\"\n",
    "        Remember that our tree is composed of a sum tree that contains the priority scores at his leaf\n",
    "        And also a data array\n",
    "        We don't use deque because it means that at each timestep our experiences change index by one.\n",
    "        We prefer to use a simple array and to overwrite when the memory is full.\n",
    "        \"\"\"\n",
    "        self.tree = SumTree(capacity)\n",
    "\n",
    "    \"\"\"\n",
    "    Store a new experience in our tree\n",
    "    Each new experience have a score of max_prority (it will be then improved when we use this exp to train our DDQN)\n",
    "    \"\"\"\n",
    "    def store(self, experience):\n",
    "        # Find the max priority\n",
    "        max_priority = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "\n",
    "        # If the max priority = 0 we can't put priority = 0 since this exp will never have a chance to be selected\n",
    "        # So we use a minimum priority\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.absolute_error_upper\n",
    "\n",
    "        self.tree.add(max_priority, experience)   # set the max p for new p\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
    "    - Then a value is uniformly sampled from each range\n",
    "    - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "    - Then, we calculate IS weights for each minibatch element\n",
    "    \"\"\"\n",
    "    def sample(self, n):\n",
    "        # Create a sample array that will contains the minibatch\n",
    "        memory_b = []\n",
    "\n",
    "        b_idx, b_ISWeights = np.empty((n,), dtype=np.int32), np.empty((n, 1), dtype=np.float32)\n",
    "\n",
    "        # Calculate the priority segment\n",
    "        # Here, as explained in the paper, we divide the Range[0, ptotal] into n ranges\n",
    "        priority_segment = self.tree.total_priority / n       # priority segment\n",
    "\n",
    "        # Here we increasing the PER_b each time we sample a new minibatch\n",
    "        self.PER_b = np.min([1., self.PER_b + self.PER_b_increment_per_sampling])  # max = 1\n",
    "\n",
    "        # Calculating the max_weight\n",
    "        p_min = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_priority\n",
    "        max_weight = (p_min * n) ** (-self.PER_b)\n",
    "\n",
    "        for i in range(n):\n",
    "            \"\"\"\n",
    "            A value is uniformly sample from each range\n",
    "            \"\"\"\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "\n",
    "            \"\"\"\n",
    "            Experience that correspond to each value is retrieved\n",
    "            \"\"\"\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "\n",
    "            #P(j)\n",
    "            sampling_probabilities = priority / self.tree.total_priority\n",
    "\n",
    "            #  IS = (1/N * 1/P(i))**b /max wi == (N*P(i))**-b  /max wi\n",
    "            b_ISWeights[i, 0] = np.power(n * sampling_probabilities, -self.PER_b)/ max_weight\n",
    "\n",
    "            b_idx[i]= index\n",
    "\n",
    "            experience = [data]\n",
    "\n",
    "            memory_b.append(experience)\n",
    "\n",
    "        return b_idx, memory_b, b_ISWeights\n",
    "\n",
    "    \"\"\"\n",
    "    Update the priorities on the tree\n",
    "    \"\"\"\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        abs_errors += self.PER_e  # convert to abs and avoid 0\n",
    "        clipped_errors = np.minimum(abs_errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.PER_a)\n",
    "\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll **deal with the empty memory problem**: we pre-populate our memory by taking random actions and storing the experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate memory\n",
    "memory = Memory(memory_size)\n",
    "\n",
    "# Render the environment\n",
    "game.new_episode()\n",
    "\n",
    "for i in range(pretrain_length):\n",
    "    # If it's the first step\n",
    "    if i == 0:\n",
    "        # First we need a state\n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "\n",
    "    # Random action\n",
    "    action = random.choice(possible_actions)\n",
    "\n",
    "    # Get the rewards\n",
    "    reward = game.make_action(action)\n",
    "\n",
    "    # Look if the episode is finished\n",
    "    done = game.is_episode_finished()\n",
    "\n",
    "    # If we're dead\n",
    "    if done:\n",
    "        # We finished the episode\n",
    "        next_state = np.zeros(state.shape)\n",
    "\n",
    "        # Add experience to memory\n",
    "        #experience = np.hstack((state, [action, reward], next_state, done))\n",
    "\n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.store(experience)\n",
    "\n",
    "        # Start a new episode\n",
    "        game.new_episode()\n",
    "\n",
    "        # First we need a state\n",
    "        state = game.get_state().screen_buffer\n",
    "\n",
    "        # Stack the frames\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "\n",
    "    else:\n",
    "        # Get the next state\n",
    "        next_state = game.get_state().screen_buffer\n",
    "        next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "        # Add experience to memory\n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.store(experience)\n",
    "\n",
    "        # Our state is now the next_state\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up Tensorboard üìä\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=/tensorboard/dddqn/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard Writer\n",
    "writer = tf.summary.FileWriter(\"./tensorboard/dddqn/1\")\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train our Agent üèÉ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "Our algorithm:\n",
    "<br>\n",
    "* Initialize the weights for DQN\n",
    "* Initialize target value weights w- <- w\n",
    "* Init the environment\n",
    "* Initialize the decay rate (that will use to reduce epsilon) \n",
    "<br><br>\n",
    "* **For** episode to max_episode **do** \n",
    "    * Make new episode\n",
    "    * Set step to 0\n",
    "    * Observe the first state $s_0$\n",
    "    <br><br>\n",
    "    * **While** step < max_steps **do**:\n",
    "        * Increase decay_rate\n",
    "        * With $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "        * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "        * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "        \n",
    "        * Sample random mini-batch from $D$: $<s, a, r, s'>$\n",
    "        * Set target $\\hat{Q} = r$ if the episode ends at $+1$, otherwise set $\\hat{Q} = r + \\gamma Q(s',argmax_{a'}{Q(s', a', w), w^-)}$\n",
    "        * Make a gradient descent step with loss $(\\hat{Q} - Q(s, a))^2$\n",
    "        * Every C steps, reset: $w^- \\leftarrow w$\n",
    "    * **endfor**\n",
    "    <br><br>\n",
    "* **endfor**\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will do the part\n",
    "With œµ select a random action atat, otherwise select at=argmaxaQ(st,a)\n",
    "\"\"\"\n",
    "def predict_action(explore_start, explore_stop, decay_rate, decay_step, state, actions):\n",
    "    ## EPSILON GREEDY STRATEGY\n",
    "    # Choose action a from state s using epsilon greedy.\n",
    "    ## First we randomize a number\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "\n",
    "    # Here we'll use an improved version of our epsilon greedy strategy used in Q-learning notebook\n",
    "    explore_probability = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * decay_step)\n",
    "\n",
    "    if (explore_probability > exp_exp_tradeoff):\n",
    "        # Make a random action (exploration)\n",
    "        action = random.choice(possible_actions)\n",
    "\n",
    "    else:\n",
    "        # Get action from Q-network (exploitation)\n",
    "        # Estimate the Qs values state\n",
    "        Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "\n",
    "        # Take the biggest Q value (= the best action)\n",
    "        choice = np.argmax(Qs)\n",
    "        action = possible_actions[int(choice)]\n",
    "\n",
    "    return action, explore_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps us to copy one set of variables to another\n",
    "# In our case we use it when we want to copy the parameters of DQN to Target_network\n",
    "# Thanks of the very good implementation of Arthur Juliani https://github.com/awjuliani\n",
    "def update_target_graph():\n",
    "\n",
    "    # Get the parameters of our DQNNetwork\n",
    "    from_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"DQNetwork\")\n",
    "\n",
    "    # Get the parameters of our Target_network\n",
    "    to_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"TargetNetwork\")\n",
    "\n",
    "    op_holder = []\n",
    "\n",
    "    # Update our target_network parameters with DQNNetwork parameters\n",
    "    for from_var,to_var in zip(from_vars,to_vars):\n",
    "        op_holder.append(to_var.assign(from_var))\n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m q_next_state \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(DQNetwork\u001b[38;5;241m.\u001b[39moutput, feed_dict \u001b[38;5;241m=\u001b[39m {DQNetwork\u001b[38;5;241m.\u001b[39minputs_: next_states_mb})\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Calculate Qtarget for all actions that state\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m q_target_next_state \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTargetNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mTargetNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_states_mb\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma * Qtarget(s',a') \u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(batch)):\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom/lib/python3.10/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()\n",
    "avg_episode_lengths = 0\n",
    "avg_episode_rewards = 0\n",
    "episode_lengths = []\n",
    "eepisode_rewards = []\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Initialize the decay rate (that will use to reduce epsilon) \n",
    "        decay_step = 0\n",
    "        \n",
    "        # Set tau = 0\n",
    "        tau = 0\n",
    "\n",
    "        # Init the game\n",
    "        game.init()\n",
    "        \n",
    "        # Update the parameters of our TargetNetwork with DQN_weights\n",
    "        update_target = update_target_graph()\n",
    "        sess.run(update_target)\n",
    "        \n",
    "        for episode in range(total_episodes):\n",
    "            # Set step to 0\n",
    "            step = 0\n",
    "            \n",
    "            # Initialize the rewards of the episode\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # Make a new episode and observe the first state\n",
    "            game.new_episode()\n",
    "            \n",
    "            state = game.get_state().screen_buffer\n",
    "            \n",
    "            # Remember that stack frame function also call our preprocess function.\n",
    "            state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                \n",
    "                # Increase the C step\n",
    "                tau += 1\n",
    "                \n",
    "                # Increase decay_step\n",
    "                decay_step +=1\n",
    "                \n",
    "                # With œµ select a random action atat, otherwise select a = argmaxQ(st,a)\n",
    "                action, explore_probability = predict_action(explore_start, explore_stop, decay_rate, decay_step, state, possible_actions)\n",
    "\n",
    "                # Do the action\n",
    "                reward = game.make_action(action)\n",
    "\n",
    "                # Look if the episode is finished\n",
    "                done = game.is_episode_finished()\n",
    "                \n",
    "                # Add the reward to total reward\n",
    "                episode_rewards.append(reward)\n",
    "\n",
    "                # If the game is finished\n",
    "                if done:\n",
    "                    # the episode ends so no next state\n",
    "                    next_state = np.zeros((120,140), dtype=int)\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "                    savestep = step\n",
    "\n",
    "                    # Set step = max_steps to end the episode\n",
    "                    step = max_steps\n",
    "\n",
    "                    # Get the total reward of the episode\n",
    "                    total_reward = np.sum(episode_rewards)\n",
    "\n",
    "                    print('Episode: {}'.format(episode), 'Step: {}'.format(savestep),\n",
    "                              'Total reward: {}'.format(total_reward),\n",
    "                              'Training loss: {:.4f}'.format(loss),\n",
    "                              'Explore P: {:.4f}'.format(explore_probability))\n",
    "                    \n",
    "                    episode_lengths.append(savestep)\n",
    "                    eepisode_rewards.append(total_reward)\n",
    "                    # Add experience to memory\n",
    "                    experience = state, action, reward, next_state, done\n",
    "                    memory.store(experience)\n",
    "\n",
    "                else:\n",
    "                    # Get the next state\n",
    "                    next_state = game.get_state().screen_buffer\n",
    "                    \n",
    "                    # Stack the frame of the next_state\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    \n",
    "\n",
    "                    # Add experience to memory\n",
    "                    experience = state, action, reward, next_state, done\n",
    "                    memory.store(experience)\n",
    "                    \n",
    "                    # st+1 is now our current state\n",
    "                    state = next_state\n",
    "\n",
    "\n",
    "                ### LEARNING PART            \n",
    "                # Obtain random mini-batch from memory\n",
    "                tree_idx, batch, ISWeights_mb = memory.sample(batch_size)\n",
    "                \n",
    "                states_mb = np.array([each[0][0] for each in batch], ndmin=3)\n",
    "                actions_mb = np.array([each[0][1] for each in batch])\n",
    "                rewards_mb = np.array([each[0][2] for each in batch]) \n",
    "                next_states_mb = np.array([each[0][3] for each in batch], ndmin=3)\n",
    "                dones_mb = np.array([each[0][4] for each in batch])\n",
    "\n",
    "                target_Qs_batch = []\n",
    "\n",
    "                \n",
    "                ### DOUBLE DQN Logic\n",
    "                # Use DQNNetwork to select the action to take at next_state (a') (action with the highest Q-value)\n",
    "                # Use TargetNetwork to calculate the Q_val of Q(s',a')\n",
    "                \n",
    "                # Get Q values for next_state \n",
    "                q_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "                \n",
    "                # Calculate Qtarget for all actions that state\n",
    "                q_target_next_state = sess.run(TargetNetwork.output, feed_dict = {TargetNetwork.inputs_: next_states_mb})\n",
    "                \n",
    "                \n",
    "                # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma * Qtarget(s',a') \n",
    "                for i in range(0, len(batch)):\n",
    "                    terminal = dones_mb[i]\n",
    "                    \n",
    "                    # We got a'\n",
    "                    action = np.argmax(q_next_state[i])\n",
    "\n",
    "                    # If we are in a terminal state, only equals reward\n",
    "                    if terminal:\n",
    "                        target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                    else:\n",
    "                        # Take the Qtarget for action a'\n",
    "                        target = rewards_mb[i] + gamma * q_target_next_state[i][action]\n",
    "                        target_Qs_batch.append(target)\n",
    "                        \n",
    "\n",
    "                targets_mb = np.array([each for each in target_Qs_batch])\n",
    "\n",
    "                \n",
    "                _, loss, absolute_errors = sess.run([DQNetwork.optimizer, DQNetwork.loss, DQNetwork.absolute_errors],\n",
    "                                    feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                               DQNetwork.target_Q: targets_mb,\n",
    "                                               DQNetwork.actions_: actions_mb,\n",
    "                                              DQNetwork.ISWeights_: ISWeights_mb})\n",
    "              \n",
    "                \n",
    "                \n",
    "                # Update priority\n",
    "                memory.batch_update(tree_idx, absolute_errors)\n",
    "                \n",
    "                \n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op, feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                   DQNetwork.target_Q: targets_mb,\n",
    "                                                   DQNetwork.actions_: actions_mb,\n",
    "                                              DQNetwork.ISWeights_: ISWeights_mb})\n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "                \n",
    "                if tau > max_tau:\n",
    "                    # Update the parameters of our TargetNetwork with DQN_weights\n",
    "                    update_target = update_target_graph()\n",
    "                    sess.run(update_target)\n",
    "                    tau = 0\n",
    "                    print(\"Model updated\")\n",
    "\n",
    "            # Save model every 5 episodes\n",
    "            if episode % 5 == 0:\n",
    "                avg_episode_lengths = [np.mean(episode_lengths[:i + 1]) for i in range(episode + 1)]\n",
    "                avg_episode_rewards = [np.mean(eepisode_rewards[:i + 1]) for i in range(episode + 1)]\n",
    "                save_path = saver.save(sess, \"./models/model.ckpt\")\n",
    "                print(\"Model Saved\")\n",
    "\n",
    "                # Clear previous output\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                # Plotting\n",
    "                fig, ax1 = plt.subplots()\n",
    "\n",
    "                ax1.set_xlabel('Number of Episodes')\n",
    "                ax1.set_ylabel('Mean Episode Length', color='tab:blue')\n",
    "                ax1.plot(range(1, episode + 2), avg_episode_lengths, color='tab:blue',label='Episode Length')\n",
    "                ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.set_ylabel('Mean Reward per Episode', color='tab:red')\n",
    "                ax2.plot(range(1, episode + 2), avg_episode_rewards, color='tab:red',label='Episode Reward')\n",
    "                ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "                fig.tight_layout()\n",
    "                ax1.legend(loc='upper right')\n",
    "                ax2.legend(loc='upper left')\n",
    "                plt.title('Training Curve')\n",
    "\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Watch our Agent play üëÄ\n",
    "Now that we trained our agent, we can test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt\n",
      "Score:  -305.0\n",
      "Score:  54.0\n",
      "Score:  -305.0\n",
      "Score:  -305.0\n",
      "Score:  -315.0\n",
      "Score:  -310.0\n",
      "Score:  -310.0\n",
      "Score:  -310.0\n",
      "Score:  -310.0\n",
      "Score:  -305.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    game = DoomGame()\n",
    "    \n",
    "    # Load the correct configuration (TESTING)\n",
    "    game.load_config('VizDoom/scenarios/basic.cfg')\n",
    "    \n",
    "    # Load the correct scenario (in our case deadly_corridor scenario)\n",
    "    game.set_doom_scenario_path('VizDoom/scenarios/basic.wad')\n",
    "    \n",
    "    game.init()    \n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, \"./models/model.ckpt\")\n",
    "    game.init()\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        game.new_episode()\n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "    \n",
    "        while not game.is_episode_finished():\n",
    "            ## EPSILON GREEDY STRATEGY\n",
    "            # Choose action a from state s using epsilon greedy.\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = np.random.rand()\n",
    "            \n",
    "\n",
    "            explore_probability = 0.01\n",
    "    \n",
    "            if (explore_probability > exp_exp_tradeoff):\n",
    "                # Make a random action (exploration)\n",
    "                action = random.choice(possible_actions)\n",
    "        \n",
    "            else:\n",
    "                # Get action from Q-network (exploitation)\n",
    "                # Estimate the Qs values state\n",
    "                Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "        \n",
    "                # Take the biggest Q value (= the best action)\n",
    "                choice = np.argmax(Qs)\n",
    "                action = possible_actions[int(choice)]\n",
    "            \n",
    "            game.make_action(action)\n",
    "            done = game.is_episode_finished()\n",
    "        \n",
    "            if done:\n",
    "                break  \n",
    "                \n",
    "            else:\n",
    "                next_state = game.get_state().screen_buffer\n",
    "                next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                state = next_state\n",
    "        \n",
    "        score = game.get_total_reward()\n",
    "        print(\"Score: \", score)\n",
    "    \n",
    "    game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
