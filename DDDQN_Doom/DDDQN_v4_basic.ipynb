{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/simoninithomas/d6adc6edb0a7f37d6323a5e3d2ab72ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "from vizdoom import *        # Doom Environment\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "import random                # Handling random number generation\n",
    "import time                  # Handling time calculation\n",
    "from skimage import transform# Help us to preprocess the frames\n",
    "\n",
    "from collections import deque# Ordered collection with ends\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "\n",
    "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create our environment üéÆ\n",
    "- Now that we imported the libraries/dependencies, we will create our environment.\n",
    "- Doom environment takes:\n",
    "    - A `configuration file` that **handle all the options** (size of the frame, possible actions...)\n",
    "    - A `scenario file`: that **generates the correct scenario** (in our case basic **but you're invited to try other scenarios**).\n",
    "- Note: We have 3 possible actions: turn left, turn right, shoot (attack)... so we don't need to do one hot encoding (thanks to <a href=\"https://stackoverflow.com/users/2237916/silgon\">silgon</a> for figuring out). \n",
    "\n",
    "<br>\n",
    "REWARDS:\n",
    "\n",
    "- death penalty = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we create our environment\n",
    "\"\"\"\n",
    "def create_environment():\n",
    "    game = DoomGame()\n",
    "\n",
    "    # Load the correct configuration\n",
    "    game.load_config('VizDoom/scenarios/basic.cfg')\n",
    "\n",
    "    # Load the correct scenario (in our case basic)\n",
    "    game.set_doom_scenario_path('VizDoom/scenarios/basic.wad')\n",
    "\n",
    "    game.set_window_visible(False) #no pop out window\n",
    "    game.init()\n",
    "\n",
    "    # Here we create an hot encoded version of our actions (3 possible actions)\n",
    "    possible_actions = np.identity(3,dtype=int).tolist()\n",
    "\n",
    "    return game, possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "files_and_directories = os.listdir(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "game, possible_actions = create_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the preprocessing functions ‚öôÔ∏è\n",
    "### preprocess_frame\n",
    "Preprocessing is an important step, <b>because we want to reduce the complexity of our states to reduce the computation time needed for training.</b>\n",
    "<br><br>\n",
    "Our steps:\n",
    "- Grayscale each of our frames (because <b> color does not add important information </b>). But this is already done by the config file.\n",
    "- Crop the screen (in our case we remove the roof because it contains no information)\n",
    "- We normalize pixel values\n",
    "- Finally we resize the preprocessed frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    preprocess_frame:\n",
    "    Take a frame.\n",
    "    Resize it.\n",
    "        __________________\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |_________________|\n",
    "\n",
    "        to\n",
    "        _____________\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        |____________|\n",
    "    Normalize it.\n",
    "\n",
    "    return preprocessed_frame\n",
    "\n",
    "    \"\"\"\n",
    "def preprocess_frame(frame):\n",
    "    # Crop the screen (remove part that contains no information)\n",
    "    # [Up: Down, Left: right]\n",
    "    cropped_frame = frame[15:-5, 20:-20]\n",
    "\n",
    "    # Check if the cropped frame has non-zero dimensions\n",
    "    if cropped_frame.size == 0:\n",
    "        # If the cropped frame has zero dimensions, return a default frame with zeros\n",
    "        return np.zeros((100, 120), dtype=np.float32)\n",
    "\n",
    "    # Normalize Pixel Values\n",
    "    normalized_frame = cropped_frame / 255.0\n",
    "\n",
    "    # Resize\n",
    "    preprocessed_frame = transform.resize(cropped_frame, [100, 120])\n",
    "\n",
    "    return preprocessed_frame # 100x120x1 frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack_frames\n",
    "üëè This part was made possible thanks to help of <a href=\"https://github.com/Miffyli\">Anssi</a><br>\n",
    "\n",
    "As explained in this really <a href=\"https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\">  good article </a> we stack frames.\n",
    "\n",
    "Stacking frames is really important because it helps us to **give have a sense of motion to our Neural Network.**\n",
    "\n",
    "- First we preprocess frame\n",
    "- Then we append the frame to the deque that automatically **removes the oldest frame**\n",
    "- Finally we **build the stacked state**\n",
    "\n",
    "This is how work stack:\n",
    "- For the first frame, we feed 4 frames\n",
    "- At each timestep, **we add the new frame to deque and then we stack them to form a new stacked frame**\n",
    "- And so on\n",
    "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/DQN/Space%20Invaders/assets/stack_frames.png\" alt=\"stack\">\n",
    "- If we're done, **we create a new stack with 4 new frames (because we are in a new episode)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4 # We stack 4 frames\n",
    "\n",
    "# Initialize deque with zero-images one array for each image\n",
    "stacked_frames  =  deque([np.zeros((100,120), dtype=int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    if state.size == 0:\n",
    "        # Return the existing stacked frames without modification\n",
    "        return np.stack(stacked_frames, axis=2), stacked_frames\n",
    "\n",
    "    # Preprocess frame\n",
    "    frame = preprocess_frame(state)\n",
    "\n",
    "    if is_new_episode:\n",
    "        # Clear our stacked_frames\n",
    "        stacked_frames = deque([np.zeros((100,120), dtype=int) for i in range(stack_size)], maxlen=4)\n",
    "\n",
    "        # Because we're in a new episode, copy the same frame 4x\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "\n",
    "    else:\n",
    "        # Append frame to deque, automatically removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "        # Build the stacked state (first dimension specifies different frames)\n",
    "        stacked_state = np.stack(stacked_frames, axis=2)\n",
    "\n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up our hyperparameters ‚öóÔ∏è\n",
    "In this part we'll set up our different hyperparameters. But when you implement a Neural Network by yourself you will **not implement hyperparamaters at once but progressively**.\n",
    "\n",
    "- First, you begin by defining the neural networks hyperparameters when you implement the model.\n",
    "- Then, you'll add the training hyperparameters when you implement the training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [100,120,4]      # Our input is a stack of 4 frames hence 100x120x4 (Width, height, channels)\n",
    "action_size = game.get_available_buttons_size()              # 3 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 1000000         # Total episodes for training\n",
    "total_timesteps = 500000     #Total timestesp for training\n",
    "max_steps = 300             # Max possible steps in an episode\n",
    "batch_size = 64\n",
    "\n",
    "# FIXED Q TARGETS HYPERPARAMETERS\n",
    "max_tau = 10000 #Tau is the C step where we update our target network\n",
    "\n",
    "# EXPLORATION HYPERPARAMETERS for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.001            # minimum exploration probability\n",
    "decay_rate = 0.00005            # exponential decay rate for exploration prob\n",
    "\n",
    "# Q LEARNING hyperparameters\n",
    "gamma = 0.95               # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "## If you have GPU change to 1million\n",
    "pretrain_length = 10             # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 10 ##100000                 # Number of experiences the Memory can keep\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Dueling Double Deep Q-learning Neural Network model (aka DDDQN) üß†\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1500/1*FkHqwA2eSGixdS-3dvVoMA.png\" alt=\"Dueling Double Deep Q Learning Model\" />\n",
    "This is our Dueling Double Deep Q-learning model:\n",
    "- We take a stack of 4 frames as input\n",
    "- It passes through 3 convnets\n",
    "- Then it is flatened\n",
    "- Then it is passed through 2 streams\n",
    "    - One that calculates V(s)\n",
    "    - The other that calculates A(s,a)\n",
    "- Finally an agregating layer\n",
    "- It outputs a Q value for each actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDDQNNet:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.name = name\n",
    "        random_var = 64\n",
    "        \n",
    "        \n",
    "        # We use tf.variable_scope here to know which network we're using (DQN or target_net)\n",
    "        # it will be useful when we will update our w- parameters (by copy the DQN parameters)\n",
    "        with tf.compat.v1.variable_scope(self.name):\n",
    "            \n",
    "            # We create the placeholders\n",
    "            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
    "            # [None, 100, 120, 4]\n",
    "            self.inputs_ = tf.compat.v1.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
    "            \n",
    "            #\n",
    "            self.ISWeights_ = tf.compat.v1.placeholder(tf.float32, [None,1], name='IS_weights')\n",
    "            \n",
    "            self.actions_ = tf.placeholder(tf.float32, [random_var, action_size], name=\"actions_\")\n",
    "            \n",
    "            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "            self.target_Q = tf.compat.v1.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            \"\"\"\n",
    "            First convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            # Input is 100x120x4\n",
    "            self.conv1 = Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=[8, 8],\n",
    "                    strides=[4, 4],\n",
    "                    padding=\"VALID\",\n",
    "                    kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                    name=\"conv1\")(self.inputs_)\n",
    "            \n",
    "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Second convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            self.conv2 = Conv2D(\n",
    "                                 filters = 64,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                 name = \"conv2\")(self.conv1_out)\n",
    "\n",
    "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            Third convnet:\n",
    "            CNN\n",
    "            ELU\n",
    "            \"\"\"\n",
    "            self.conv3 = Conv2D(\n",
    "                                 filters = 128,\n",
    "                                 kernel_size = [4,4],\n",
    "                                 strides = [2,2],\n",
    "                                 padding = \"VALID\",\n",
    "                                kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                 name = \"conv3\")(self.conv2_out)\n",
    "\n",
    "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
    "            \n",
    "            \n",
    "            self.flatten = Flatten(data_format='channels_last')(self.conv3)\n",
    "            \n",
    "            \n",
    "            ## Here we separate into two streams\n",
    "            # The one that calculate V(s)\n",
    "            self.value_fc = Dense(\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"value_fc\")(self.flatten)\n",
    "            \n",
    "            self.value = Dense(\n",
    "                                        units = 1,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"value\")(self.value_fc)\n",
    "            \n",
    "            # The one that calculate A(s,a)\n",
    "            self.advantage_fc = Dense(\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"advantage_fc\")(self.flatten)\n",
    "            \n",
    "            self.advantage = Dense(\n",
    "                                        units = self.action_size,\n",
    "                                        activation = None,\n",
    "                                        kernel_initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"),\n",
    "                                name=\"advantages\")(self.advantage_fc)\n",
    "            \n",
    "            # Agregating layer\n",
    "            # Q(s,a) = V(s) + (A(s,a) - 1/|A| * sum A(s,a'))\n",
    "            self.output = self.value + tf.subtract(self.advantage, tf.reduce_mean(self.advantage, axis=1, keepdims=True))\n",
    "              \n",
    "            # Q is our predicted Q value.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_), axis=1)\n",
    "            \n",
    "            # The loss is modified because of PER \n",
    "            self.absolute_errors = tf.abs(self.target_Q - self.Q)# for updating Sumtree\n",
    "            \n",
    "            self.loss = tf.reduce_mean(self.ISWeights_ * tf.math.squared_difference(self.target_Q, self.Q))\n",
    "            \n",
    "            self.optimizer = tf.compat.v1.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"DQNetwork\")\n",
    "\n",
    "# Instantiate the target network\n",
    "TargetNetwork = DDDQNNet(state_size, action_size, learning_rate, name=\"TargetNetwork\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prioritized Experience Replay üîÅ\n",
    "Now that we create our Neural Network, **we need to implement the Prioritized Experience Replay method.** <br>\n",
    "\n",
    "As explained in the article, **we can't use a simple array to do that because sampling from it will be not efficient, so we use a binary tree data type (in a binary tree each node has no + than 2 children).** More precisely, a sumtree, which is a binary tree where parents nodes are the sum of the children nodes.\n",
    "\n",
    "If you don't know what is a binary tree check this awesome video https://www.youtube.com/watch?v=oSWTXtMglKE\n",
    "\n",
    "\n",
    "This SumTree implementation was taken from Morvan Zhou in his chinese course about Reinforcement Learning\n",
    "\n",
    "To summarize:\n",
    "- **Step 1**: We construct a SumTree, which is a Binary Sum tree where leaves contains the priorities and a data array where index points to the index of leaves.\n",
    "    <img src=\"https://cdn-images-1.medium.com/max/1200/1*Go9DNr7YY-wMGdIQ7HQduQ.png\" alt=\"SumTree\"/>\n",
    "    <br><br>\n",
    "    - **def __init__**: Initialize our SumTree data object with all nodes = 0 and data (data array) with all = 0.\n",
    "    - **def add**: add our priority score in the sumtree leaf and experience (S, A, R, S', Done) in data.\n",
    "    - **def update**: we update the leaf priority score and propagate through tree.\n",
    "    - **def get_leaf**: retrieve priority score, index and experience associated with a leaf.\n",
    "    - **def total_priority**: get the root node value to calculate the total priority score of our replay buffer.\n",
    "<br><br>\n",
    "- **Step 2**: We create a Memory object that will contain our sumtree and data.\n",
    "    - **def __init__**: generates our sumtree and data by instantiating the SumTree object.\n",
    "    - **def store**: we store a new experience in our tree. Each new experience will **have priority = max_priority** (and then this priority will be corrected during the training (when we'll calculating the TD error hence the priority score).\n",
    "    - **def sample**:\n",
    "         - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
    "         - Then a value is uniformly sampled from each range\n",
    "         - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "         - Then, we calculate IS weights for each minibatch element\n",
    "    - **def update_batch**: update the priorities on the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version of Morvan Zhou:\n",
    "    https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5.2_Prioritized_Replay_DQN/RL_brain.py\n",
    "    \"\"\"\n",
    "    data_pointer = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Here we initialize the tree with all nodes = 0, and initialize the data with all values = 0\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # Number of leaf nodes (final nodes) that contains experiences\n",
    "\n",
    "        # Generate the tree with all nodes values = 0\n",
    "        # To understand this calculation (2 * capacity - 1) look at the schema above\n",
    "        # Remember we are in a binary node (each node has max 2 children) so 2x size of leaf (capacity) - 1 (root node)\n",
    "        # Parent nodes = capacity - 1\n",
    "        # Leaf nodes = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "\n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "        0  0 0  0  [Size: capacity] it's at this line that there is the priorities score (aka pi)\n",
    "        \"\"\"\n",
    "\n",
    "        # Contains the experiences (so the size of data is capacity)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Here we add our priority score in the sumtree leaf and add the experience in data\n",
    "    \"\"\"\n",
    "    def add(self, priority, data):\n",
    "        # Look at what index we want to put the experience\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "\n",
    "        \"\"\" tree:\n",
    "            0\n",
    "           / \\\n",
    "          0   0\n",
    "         / \\ / \\\n",
    "tree_index  0 0  0  We fill the leaves from left to right\n",
    "        \"\"\"\n",
    "\n",
    "        # Update data frame\n",
    "        self.data[self.data_pointer] = data\n",
    "\n",
    "        # Update the leaf\n",
    "        self.update (tree_index, priority)\n",
    "\n",
    "        # Add 1 to data_pointer\n",
    "        self.data_pointer += 1\n",
    "\n",
    "        if self.data_pointer >= self.capacity:  # If we're above the capacity, you go back to first index (we overwrite)\n",
    "            self.data_pointer = 0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Update the leaf priority score and propagate the change through tree\n",
    "    \"\"\"\n",
    "    def update(self, tree_index, priority):\n",
    "        # Change = new priority score - former priority score\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "\n",
    "        # then propagate the change through tree\n",
    "        while tree_index != 0:    # this method is faster than the recursive loop in the reference code\n",
    "\n",
    "            \"\"\"\n",
    "            Here we want to access the line above\n",
    "            THE NUMBERS IN THIS TREE ARE THE INDEXES NOT THE PRIORITY VALUES\n",
    "\n",
    "                0\n",
    "               / \\\n",
    "              1   2\n",
    "             / \\ / \\\n",
    "            3  4 5  [6]\n",
    "\n",
    "            If we are in leaf at index 6, we updated the priority score\n",
    "            We need then to update index 2 node\n",
    "            So tree_index = (tree_index - 1) // 2\n",
    "            tree_index = (6-1)//2\n",
    "            tree_index = 2 (because // round the result)\n",
    "            \"\"\"\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Here we get the leaf_index, priority value of that leaf and experience associated with that index\n",
    "    \"\"\"\n",
    "    def get_leaf(self, v):\n",
    "        \"\"\"\n",
    "        Tree structure and array storage:\n",
    "        Tree index:\n",
    "             0         -> storing priority sum\n",
    "            / \\\n",
    "          1     2\n",
    "         / \\   / \\\n",
    "        3   4 5   6    -> storing priority for experiences\n",
    "        Array type for storing:\n",
    "        [0,1,2,3,4,5,6]\n",
    "        \"\"\"\n",
    "        parent_index = 0\n",
    "\n",
    "        while True: # the while loop is faster than the method in the reference code\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "\n",
    "            # If we reach bottom, end the search\n",
    "            if left_child_index >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "\n",
    "            else: # downward search, always search for a higher priority node\n",
    "\n",
    "                if v <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "\n",
    "                else:\n",
    "                    v -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "\n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "\n",
    "        return leaf_index, self.tree[leaf_index], self.data[data_index]\n",
    "\n",
    "    @property\n",
    "    def total_priority(self):\n",
    "        return self.tree[0] # Returns the root node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't use deque anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    \"\"\"\n",
    "    This SumTree code is modified version and the original code is from:\n",
    "    https://github.com/jaara/AI-blog/blob/master/Seaquest-DDQN-PER.py\n",
    "    \"\"\"\n",
    "    PER_e = 0.01  # Hyperparameter that we use to avoid some experiences to have 0 probability of being taken\n",
    "    PER_a = 0.6  # Hyperparameter that we use to make a tradeoff between taking only exp with high priority and sampling randomly\n",
    "    PER_b = 0.4  # importance-sampling, from initial value increasing to 1\n",
    "\n",
    "    PER_b_increment_per_sampling = 0.001\n",
    "\n",
    "    absolute_error_upper = 1.  # clipped abs error\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Making the tree\n",
    "        \"\"\"\n",
    "        Remember that our tree is composed of a sum tree that contains the priority scores at his leaf\n",
    "        And also a data array\n",
    "        We don't use deque because it means that at each timestep our experiences change index by one.\n",
    "        We prefer to use a simple array and to overwrite when the memory is full.\n",
    "        \"\"\"\n",
    "        self.tree = SumTree(capacity)\n",
    "\n",
    "    \"\"\"\n",
    "    Store a new experience in our tree\n",
    "    Each new experience have a score of max_prority (it will be then improved when we use this exp to train our DDQN)\n",
    "    \"\"\"\n",
    "    def store(self, experience):\n",
    "        # Find the max priority\n",
    "        max_priority = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "\n",
    "        # If the max priority = 0 we can't put priority = 0 since this exp will never have a chance to be selected\n",
    "        # So we use a minimum priority\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.absolute_error_upper\n",
    "\n",
    "        self.tree.add(max_priority, experience)   # set the max p for new p\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - First, to sample a minibatch of k size, the range [0, priority_total] is / into k ranges.\n",
    "    - Then a value is uniformly sampled from each range\n",
    "    - We search in the sumtree, the experience where priority score correspond to sample values are retrieved from.\n",
    "    - Then, we calculate IS weights for each minibatch element\n",
    "    \"\"\"\n",
    "    def sample(self, n):\n",
    "        # Create a sample array that will contains the minibatch\n",
    "        memory_b = []\n",
    "\n",
    "        b_idx, b_ISWeights = np.empty((n,), dtype=np.int32), np.empty((n, 1), dtype=np.float32)\n",
    "\n",
    "        # Calculate the priority segment\n",
    "        # Here, as explained in the paper, we divide the Range[0, ptotal] into n ranges\n",
    "        priority_segment = self.tree.total_priority / n       # priority segment\n",
    "\n",
    "        # Here we increasing the PER_b each time we sample a new minibatch\n",
    "        self.PER_b = np.min([1., self.PER_b + self.PER_b_increment_per_sampling])  # max = 1\n",
    "\n",
    "        # Calculating the max_weight\n",
    "        p_min = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_priority\n",
    "        max_weight = (p_min * n) ** (-self.PER_b)\n",
    "\n",
    "        for i in range(n):\n",
    "            \"\"\"\n",
    "            A value is uniformly sample from each range\n",
    "            \"\"\"\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "\n",
    "            \"\"\"\n",
    "            Experience that correspond to each value is retrieved\n",
    "            \"\"\"\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "\n",
    "            #P(j)\n",
    "            sampling_probabilities = priority / self.tree.total_priority\n",
    "\n",
    "            #  IS = (1/N * 1/P(i))**b /max wi == (N*P(i))**-b  /max wi\n",
    "            b_ISWeights[i, 0] = np.power(n * sampling_probabilities, -self.PER_b)/ max_weight\n",
    "\n",
    "            b_idx[i]= index\n",
    "\n",
    "            experience = [data]\n",
    "\n",
    "            memory_b.append(experience)\n",
    "\n",
    "        return b_idx, memory_b, b_ISWeights\n",
    "\n",
    "    \"\"\"\n",
    "    Update the priorities on the tree\n",
    "    \"\"\"\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        abs_errors += self.PER_e  # convert to abs and avoid 0\n",
    "        clipped_errors = np.minimum(abs_errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.PER_a)\n",
    "\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll **deal with the empty memory problem**: we pre-populate our memory by taking random actions and storing the experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate memory\n",
    "memory = Memory(memory_size)\n",
    "\n",
    "# Render the environment\n",
    "game.new_episode()\n",
    "\n",
    "for i in range(pretrain_length):\n",
    "    # If it's the first step\n",
    "    if i == 0:\n",
    "        # First we need a state\n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "\n",
    "    # Random action\n",
    "    action = random.choice(possible_actions)\n",
    "\n",
    "    # Get the rewards\n",
    "    reward = game.make_action(action)\n",
    "\n",
    "    # Look if the episode is finished\n",
    "    done = game.is_episode_finished()\n",
    "\n",
    "    # If we're dead\n",
    "    if done:\n",
    "        # We finished the episode\n",
    "        next_state = np.zeros(state.shape)\n",
    "\n",
    "        # Add experience to memory\n",
    "        #experience = np.hstack((state, [action, reward], next_state, done))\n",
    "\n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.store(experience)\n",
    "\n",
    "        # Start a new episode\n",
    "        game.new_episode()\n",
    "\n",
    "        # First we need a state\n",
    "        state = game.get_state().screen_buffer\n",
    "\n",
    "        # Stack the frames\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "\n",
    "    else:\n",
    "        # Get the next state\n",
    "        next_state = game.get_state().screen_buffer\n",
    "        next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "        # Add experience to memory\n",
    "        experience = state, action, reward, next_state, done\n",
    "        memory.store(experience)\n",
    "\n",
    "        # Our state is now the next_state\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up Tensorboard üìä\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=/tensorboard/dddqn/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard Writer\n",
    "writer = tf.summary.FileWriter(\"./tensorboard/dddqn/1\")\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train our Agent üèÉ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "Our algorithm:\n",
    "<br>\n",
    "* Initialize the weights for DQN\n",
    "* Initialize target value weights w- <- w\n",
    "* Init the environment\n",
    "* Initialize the decay rate (that will use to reduce epsilon) \n",
    "<br><br>\n",
    "* **For** episode to max_episode **do** \n",
    "    * Make new episode\n",
    "    * Set step to 0\n",
    "    * Observe the first state $s_0$\n",
    "    <br><br>\n",
    "    * **While** step < max_steps **do**:\n",
    "        * Increase decay_rate\n",
    "        * With $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "        * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "        * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "        \n",
    "        * Sample random mini-batch from $D$: $<s, a, r, s'>$\n",
    "        * Set target $\\hat{Q} = r$ if the episode ends at $+1$, otherwise set $\\hat{Q} = r + \\gamma Q(s',argmax_{a'}{Q(s', a', w), w^-)}$\n",
    "        * Make a gradient descent step with loss $(\\hat{Q} - Q(s, a))^2$\n",
    "        * Every C steps, reset: $w^- \\leftarrow w$\n",
    "    * **endfor**\n",
    "    <br><br>\n",
    "* **endfor**\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will do the part\n",
    "With œµ select a random action atat, otherwise select at=argmaxaQ(st,a)\n",
    "\"\"\"\n",
    "def predict_action(explore_start, explore_stop, decay_rate, decay_step, state, actions):\n",
    "    ## EPSILON GREEDY STRATEGY\n",
    "    # Choose action a from state s using epsilon greedy.\n",
    "    ## First we randomize a number\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "\n",
    "    # Here we'll use an improved version of our epsilon greedy strategy used in Q-learning notebook\n",
    "    explore_probability = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * decay_step)\n",
    "\n",
    "    if (explore_probability > exp_exp_tradeoff):\n",
    "        # Make a random action (exploration)\n",
    "        action = random.choice(possible_actions)\n",
    "\n",
    "    else:\n",
    "        # Get action from Q-network (exploitation)\n",
    "        # Estimate the Qs values state\n",
    "        Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "\n",
    "        # Take the biggest Q value (= the best action)\n",
    "        choice = np.argmax(Qs)\n",
    "        action = possible_actions[int(choice)]\n",
    "\n",
    "    return action, explore_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function helps us to copy one set of variables to another\n",
    "# In our case we use it when we want to copy the parameters of DQN to Target_network\n",
    "# Thanks of the very good implementation of Arthur Juliani https://github.com/awjuliani\n",
    "def update_target_graph():\n",
    "\n",
    "    # Get the parameters of our DQNNetwork\n",
    "    from_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"DQNetwork\")\n",
    "\n",
    "    # Get the parameters of our Target_network\n",
    "    to_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"TargetNetwork\")\n",
    "\n",
    "    op_holder = []\n",
    "\n",
    "    # Update our target_network parameters with DQNNetwork parameters\n",
    "    for from_var,to_var in zip(from_vars,to_vars):\n",
    "        op_holder.append(to_var.assign(from_var))\n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[237], line 158\u001b[0m\n\u001b[1;32m    152\u001b[0m         target_Qs_batch\u001b[38;5;241m.\u001b[39mappend(target)\n\u001b[1;32m    155\u001b[0m targets_mb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([each \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m target_Qs_batch])\n\u001b[0;32m--> 158\u001b[0m _, loss, absolute_errors \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsolute_errors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates_mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_Q\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mDQNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mISWeights_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mISWeights_mb\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Update priority\u001b[39;00m\n\u001b[1;32m    167\u001b[0m memory\u001b[38;5;241m.\u001b[39mbatch_update(tree_idx, absolute_errors)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:972\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    975\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:1215\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1215\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:1395\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:1402\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1401\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1404\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:1385\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1385\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Doom2/lib/python3.10/site-packages/tensorflow/python/client/session.py:1478\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()\n",
    "avg_episode_lengths = 0\n",
    "avg_episode_rewards = 0\n",
    "acc_timesteps = 0\n",
    "episode_lengths = []\n",
    "eepisode_rewards = []\n",
    "\n",
    "plot_dir = './logs/dddqn/plots'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "figure_file = os.path.join(plot_dir, 'test.png')\n",
    "\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Initialize the decay rate (that will use to reduce epsilon) \n",
    "        decay_step = 0\n",
    "        \n",
    "        # Set tau = 0\n",
    "        tau = 0\n",
    "\n",
    "        # Init the game\n",
    "        game.init()\n",
    "        \n",
    "        # Update the parameters of our TargetNetwork with DQN_weights\n",
    "        update_target = update_target_graph()\n",
    "        sess.run(update_target)\n",
    "        while acc_timesteps < total_timesteps:\n",
    "            for episode in range(total_episodes):\n",
    "                if acc_timesteps > total_timesteps:\n",
    "                    break\n",
    "                # Set step to 0\n",
    "                step = 0\n",
    "                \n",
    "                # Initialize the rewards of the episode\n",
    "                episode_rewards = []\n",
    "                \n",
    "                # Make a new episode and observe the first state\n",
    "                game.new_episode()\n",
    "                \n",
    "                state = game.get_state().screen_buffer\n",
    "                \n",
    "                # Remember that stack frame function also call our preprocess function.\n",
    "                state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "            \n",
    "                while step < max_steps:\n",
    "                    if acc_timesteps > total_timesteps:\n",
    "                        break\n",
    "                    step += 1\n",
    "                    acc_timesteps += 1\n",
    "                    \n",
    "                    # Increase the C step\n",
    "                    tau += 1\n",
    "                    \n",
    "                    # Increase decay_step\n",
    "                    decay_step +=1\n",
    "                    \n",
    "                    # With œµ select a random action atat, otherwise select a = argmaxQ(st,a)\n",
    "                    action, explore_probability = predict_action(explore_start, explore_stop, decay_rate, decay_step, state, possible_actions)\n",
    "\n",
    "                    # Do the action\n",
    "                    reward = game.make_action(action)\n",
    "\n",
    "                    # Look if the episode is finished\n",
    "                    done = game.is_episode_finished()\n",
    "                    \n",
    "                    # Add the reward to total reward\n",
    "                    episode_rewards.append(reward)\n",
    "\n",
    "                    # If the game is finished\n",
    "                    if done:\n",
    "                        # the episode ends so no next state\n",
    "                        next_state = np.zeros((120,140), dtype=int)\n",
    "                        next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "\n",
    "                        savestep = step\n",
    "\n",
    "                        # Set step = max_steps to end the episode\n",
    "                        step = max_steps\n",
    "\n",
    "                        # Get the total reward of the episode\n",
    "                        total_reward = np.sum(episode_rewards)\n",
    "\n",
    "                        print('Episode: {}'.format(episode), 'Step: {}'.format(savestep), 'Acc Step: {}'.format(acc_timesteps),\n",
    "                                'Total reward: {}'.format(total_reward),\n",
    "                                'Training loss: {:.4f}'.format(loss),\n",
    "                                'Explore P: {:.4f}'.format(explore_probability))\n",
    "                        \n",
    "                        episode_lengths.append(savestep)\n",
    "                        eepisode_rewards.append(total_reward)\n",
    "                        # Add experience to memory\n",
    "                        experience = state, action, reward, next_state, done\n",
    "                        memory.store(experience)\n",
    "\n",
    "                    else:\n",
    "                        # Get the next state\n",
    "                        next_state = game.get_state().screen_buffer\n",
    "                        \n",
    "                        # Stack the frame of the next_state\n",
    "                        next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                        \n",
    "\n",
    "                        # Add experience to memory\n",
    "                        experience = state, action, reward, next_state, done\n",
    "                        memory.store(experience)\n",
    "                        \n",
    "                        # st+1 is now our current state\n",
    "                        state = next_state\n",
    "\n",
    "\n",
    "                    ### LEARNING PART            \n",
    "                    # Obtain random mini-batch from memory\n",
    "                    tree_idx, batch, ISWeights_mb = memory.sample(batch_size)\n",
    "                    \n",
    "                    states_mb = np.array([each[0][0] for each in batch], ndmin=3)\n",
    "                    actions_mb = np.array([each[0][1] for each in batch])\n",
    "                    rewards_mb = np.array([each[0][2] for each in batch]) \n",
    "                    next_states_mb = np.array([each[0][3] for each in batch], ndmin=3)\n",
    "                    dones_mb = np.array([each[0][4] for each in batch])\n",
    "\n",
    "                    target_Qs_batch = []\n",
    "\n",
    "                    \n",
    "                    ### DOUBLE DQN Logic\n",
    "                    # Use DQNNetwork to select the action to take at next_state (a') (action with the highest Q-value)\n",
    "                    # Use TargetNetwork to calculate the Q_val of Q(s',a')\n",
    "                    \n",
    "                    # Get Q values for next_state \n",
    "                    q_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "                    \n",
    "                    # Calculate Qtarget for all actions that state\n",
    "                    q_target_next_state = sess.run(TargetNetwork.output, feed_dict = {TargetNetwork.inputs_: next_states_mb})\n",
    "                    \n",
    "                    \n",
    "                    # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma * Qtarget(s',a') \n",
    "                    for i in range(0, len(batch)):\n",
    "                        terminal = dones_mb[i]\n",
    "                        \n",
    "                        # We got a'\n",
    "                        action = np.argmax(q_next_state[i])\n",
    "\n",
    "                        # If we are in a terminal state, only equals reward\n",
    "                        if terminal:\n",
    "                            target_Qs_batch.append(rewards_mb[i])\n",
    "                            \n",
    "                        else:\n",
    "                            # Take the Qtarget for action a'\n",
    "                            target = rewards_mb[i] + gamma * q_target_next_state[i][action]\n",
    "                            target_Qs_batch.append(target)\n",
    "                            \n",
    "\n",
    "                    targets_mb = np.array([each for each in target_Qs_batch])\n",
    "\n",
    "                    \n",
    "                    _, loss, absolute_errors = sess.run([DQNetwork.optimizer, DQNetwork.loss, DQNetwork.absolute_errors],\n",
    "                                        feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                DQNetwork.target_Q: targets_mb,\n",
    "                                                DQNetwork.actions_: actions_mb,\n",
    "                                                DQNetwork.ISWeights_: ISWeights_mb})\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    # Update priority\n",
    "                    memory.batch_update(tree_idx, absolute_errors)\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        # Write TF Summaries\n",
    "                        summary = sess.run(write_op, feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                        DQNetwork.target_Q: targets_mb,\n",
    "                                                        DQNetwork.actions_: actions_mb,\n",
    "                                                    DQNetwork.ISWeights_: ISWeights_mb})\n",
    "                        writer.add_summary(summary, episode)\n",
    "                        writer.flush()\n",
    "                    except tf.errors.InvalidArgumentError as e:\n",
    "                        print(\"An error occurred:\", e)\n",
    "                        print(\"Skipping the code and continuing...\")\n",
    "                    \n",
    "                    if tau > max_tau:\n",
    "                        # Update the parameters of our TargetNetwork with DQN_weights\n",
    "                        update_target = update_target_graph()\n",
    "                        sess.run(update_target)\n",
    "                        tau = 0\n",
    "                        print(\"Model updated\")\n",
    "                    \n",
    "                    # Save model every 16 timesteps\n",
    "                    if acc_timesteps % 16 == 0:\n",
    "                        avg_episode_lengths = [np.mean(episode_lengths[:i + 1]) for i in range(episode + 1)]\n",
    "                        avg_episode_rewards = [np.mean(eepisode_rewards[:i + 1]) for i in range(episode + 1)]\n",
    "                        save_path = saver.save(sess, \"./models/model.ckpt\")\n",
    "\n",
    "                        # Clear previous output\n",
    "                        clear_output(wait=True)\n",
    "                        \n",
    "                        # Plotting\n",
    "                        fig, ax1 = plt.subplots()\n",
    "\n",
    "                        ax1.set_xlabel('Number of Episodes')\n",
    "                        ax1.set_ylabel('Mean Episode Length', color='tab:blue')\n",
    "                        ax1.plot(range(1, episode + 2), avg_episode_lengths, color='tab:blue',label='Episode Length')\n",
    "                        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "                        ax2 = ax1.twinx()\n",
    "                        ax2.set_ylabel('Mean Reward per Episode', color='tab:red')\n",
    "                        ax2.plot(range(1, episode + 2), avg_episode_rewards, color='tab:red',label='Episode Reward')\n",
    "                        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "                        fig.tight_layout()\n",
    "                        ax1.legend(loc='upper right')\n",
    "                        ax2.legend(loc='upper left')\n",
    "                        plt.title('Training Curve')\n",
    "\n",
    "                        # Save the plot with a filename based on acc_timesteps\n",
    "                        save_filename = f\"performance_{acc_timesteps:06d}.png\"\n",
    "                        save_path = os.path.join(plot_dir, save_filename)\n",
    "                        plt.savefig(save_path)\n",
    "\n",
    "\n",
    "                        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Watch our Agent play üëÄ\n",
    "Now that we trained our agent, we can test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model.ckpt\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     choice \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Qs)\n\u001b[1;32m     43\u001b[0m     action \u001b[38;5;241m=\u001b[39m possible_actions[\u001b[38;5;28mint\u001b[39m(choice)]\n\u001b[0;32m---> 45\u001b[0m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m done \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mis_episode_finished()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "\u001b[0;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    game = DoomGame()\n",
    "    \n",
    "    # Load the correct configuration (TESTING)\n",
    "    game.load_config('VizDoom/scenarios/basic.cfg')\n",
    "    \n",
    "    # Load the correct scenario (in our case deadly_corridor scenario)\n",
    "    game.set_doom_scenario_path('VizDoom/scenarios/basic.wad')\n",
    "    \n",
    "    game.init()    \n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, \"./models/model.ckpt\")\n",
    "    game.init()\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        game.new_episode()\n",
    "        state = game.get_state().screen_buffer\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "    \n",
    "        while not game.is_episode_finished():\n",
    "            ## EPSILON GREEDY STRATEGY\n",
    "            # Choose action a from state s using epsilon greedy.\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = np.random.rand()\n",
    "            \n",
    "\n",
    "            explore_probability = 0.01\n",
    "    \n",
    "            if (explore_probability > exp_exp_tradeoff):\n",
    "                # Make a random action (exploration)\n",
    "                action = random.choice(possible_actions)\n",
    "        \n",
    "            else:\n",
    "                # Get action from Q-network (exploitation)\n",
    "                # Estimate the Qs values state\n",
    "                Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "        \n",
    "                # Take the biggest Q value (= the best action)\n",
    "                choice = np.argmax(Qs)\n",
    "                action = possible_actions[int(choice)]\n",
    "            \n",
    "            game.make_action(action)\n",
    "            done = game.is_episode_finished()\n",
    "        \n",
    "            if done:\n",
    "                break  \n",
    "                \n",
    "            else:\n",
    "                next_state = game.get_state().screen_buffer\n",
    "                next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                state = next_state\n",
    "        \n",
    "        score = game.get_total_reward()\n",
    "        print(\"Score: \", score)\n",
    "    \n",
    "    game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
