{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Records CartPole Performance\n",
    "\n",
    "**Please expand the cells to view the code!**\n",
    "\n",
    "### Description\n",
    "This notebook records an episode of the CartPole when using a saved .pt model and saved it as an .mp4 file. \n",
    "\n",
    "### How to Run\n",
    "Please make sure to change the model directory to the model you want to run, and change the video directory to where you would like the video to be saved.\n",
    "\n",
    "### Citations\n",
    "Kang, C., 2021. REINFORCE on CartPole-v0 [Online]. Chan`s Jupyter. Available from: https://goodboychan.github.io/python/reinforcement_learning/pytorch/udacity/2021/05/12/REINFORCE-CartPole.html [Accessed 8 May 2024].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import base64, io\n",
    "\n",
    "# For visualization\n",
    "from gym.wrappers.monitoring import video_recorder\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "import glob\n",
    "\n",
    "\n",
    "class DDDQNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc_value = nn.Linear(64, 256)\n",
    "        self.value = nn.Linear(256, 1)\n",
    "\n",
    "        self.fc_adv = nn.Linear(64, 256)\n",
    "        self.adv = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.fc1(x))\n",
    "        value = self.relu(self.fc_value(y))\n",
    "        adv = self.relu(self.fc_adv(y))\n",
    "\n",
    "        value = self.value(value)\n",
    "        adv = self.adv(adv)\n",
    "\n",
    "        output = value + adv - torch.mean(adv, dim=1, keepdim=True)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def select_action(self, x):\n",
    "        with torch.no_grad():\n",
    "            Q = self.forward(x)\n",
    "            action_index = torch.argmax(Q, dim=1)\n",
    "        return action_index.item()\n",
    "    \n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(4, 32)\n",
    "        self.layer2 = nn.Linear(32, 2)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.layer1(state))\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video_of_model(model_path,\n",
    "                        model_name, episodes, env_name=\"CartPole-v1\", agent=\"CartPole\"):\n",
    "    if model_name == \"reinforce\":\n",
    "        policy = Net()\n",
    "    else:\n",
    "        policy = DDDQNet()\n",
    "\n",
    "    policy = torch.load(model_path)\n",
    "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
    "    vid = video_recorder.VideoRecorder(env, path=f\"./video/{agent}_{model_name}_{episodes}.mp4\")\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    reward = 0\n",
    "    for t in range(2000):\n",
    "        vid.capture_frame()\n",
    "        tensor_state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "\n",
    "        if model_name == \"reinforce\":\n",
    "            action_logits = policy(tensor_state)\n",
    "            action = torch.argmax(action_logits, dim=1).item()\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            reward += reward\n",
    "        else: \n",
    "            action = policy.select_action(tensor_state)\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            reward += reward\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"Reward earned: \", reward)\n",
    "            print(\"t: \", t)\n",
    "            break\n",
    "\n",
    "    vid.close()\n",
    "    env.close()\n",
    "\n",
    "    \n",
    "record_video_of_model(model_path=\"./models/random_replay/CN8e-05_LR1e-05_B128/E1500.pt\",\n",
    "                        model_name=\"dddqn_random_rep\",\n",
    "                        episodes=1500)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "record_video_of_model(model_path=\"./models/prioritised_replay/CN8e-05_LR1e-05_B128/E_2600.pt\",\n",
    "                    model_name=\"dddqn_prioritised_rep\",\n",
    "                    episodes=2600)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_video_of_model(model_path=\"./models/reinforce/LR0.001/E_1700.pt\",\n",
    "                    model_name=\"reinforce\",\n",
    "                    episodes=1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_video_of_model(model_path=\"./models/reinforce/LR0.001/E_1400.pt\",\n",
    "                    model_name=\"reinforce\",\n",
    "                    episodes=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
